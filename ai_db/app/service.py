# app/service.py
"""
ë©”ì¸ ì„œë¹„ìŠ¤ ë¡œì§
- case_typeì´ ìˆìœ¼ë©´ ê·¸ëŒ€ë¡œ ì‚¬ìš© (í•˜ìœ„ í˜¸í™˜)
- case_typeì´ ì—†ìœ¼ë©´ ìë™ ë¶„ë¥˜
"""
import pandas as pd
import faiss
import re
from sentence_transformers import SentenceTransformer
from app.llm.summarizer import generate_case_summary
from app.schemas import CaseSummaryResponse, CaseFullTextResponse
from app.classifier import infer_case_type, get_case_type_label, get_case_type_description
from app.search_engine import get_search_subset, search_with_fallback

# ------------------------
# 0ï¸âƒ£ ë°ì´í„° ë¡œë“œ
# ------------------------
print("\n" + "=" * 80)
print("ğŸš€ ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì¤‘...")
print("=" * 80)

df_analysis = pd.read_parquet(
    r"C:\LawAI\notebooks\korean_precedents_embedded.parquet",
    engine="pyarrow"
)

df_full = pd.read_csv(
    r"C:\LawAI\notebooks\korean_precedents_clean.csv"
)

print(f"âœ… Parquet ë¡œë“œ: {len(df_analysis)} rows")
print(f"âœ… CSV ë¡œë“œ: {len(df_full)} rows")

# âœ… ì‚¬ê±´ë²ˆí˜¸ â†’ ì¸ë±ìŠ¤ ë§¤í•‘
case_id_to_idx = {}
for idx, row in df_full.iterrows():
    case_num = row.get("ì‚¬ê±´ë²ˆí˜¸")
    if pd.notna(case_num):
        normalized = str(case_num).strip()
        if normalized:
            case_id_to_idx[normalized] = idx

print(f"âœ… case_id_to_idx í¬ê¸°: {len(case_id_to_idx)}")

# ì‚¬ê±´ì¢…ë¥˜ëª… ë¶„í¬ ì¶œë ¥
print("\nğŸ“Š ì‚¬ê±´ì¢…ë¥˜ëª… ë¶„í¬:")
print(df_analysis["ì‚¬ê±´ì¢…ë¥˜ëª…"].value_counts().head(10))
print("=" * 80 + "\n")

faiss_index = faiss.read_index(
    r"C:\LawAI\notebooks\case_index.faiss"
)

model = SentenceTransformer(
    "snunlp/KR-SBERT-V40K-klueNLI-augSTS"
)

# ------------------------
# íŒê²° ê²°ê³¼ ì¶”ì¶œ
# ------------------------
def extract_decision_result(case_text: str) -> str:
    if not case_text:
        return "íŒë‹¨ë¶ˆëª…"

    order_match = re.search(
        r"ã€ì£¼\s*ë¬¸ã€‘(.+?)(ã€ì´\s*ìœ ã€‘|$)",
        case_text,
        re.DOTALL
    )
    target = order_match.group(1) if order_match else case_text

    patterns = {
        "íŒŒê¸°í™˜ì†¡": r"(íŒŒê¸°|íŒŒí›¼).*(í™˜ì†¡|ì°¨ë ¤)",
        "ìƒê³ ê¸°ê°": r"ìƒê³ .*ê¸°ê°",
        "ì¸ìš©": r"ì²­êµ¬.*ì¸ìš©|ì›ê³ .*ìŠ¹ì†Œ",
        "ê¸°ê°": r"ì²­êµ¬.*ê¸°ê°",
    }

    for label, pattern in patterns.items():
        if re.search(pattern, target):
            return label
    return "íŒë‹¨ë¶ˆëª…"

DECISION_RISK_MAP = {
    "ìƒê³ ê¸°ê°": 0.85,
    "ê¸°ê°": 0.8,
    "íŒŒê¸°í™˜ì†¡": 0.5,
    "ì¸ìš©": 0.2,
    "íŒë‹¨ë¶ˆëª…": 0.5
}

def similarity_band(sim: float) -> str:
    if sim >= 0.85:
        return "ë§¤ìš° ë†’ì€ ìœ ì‚¬ë„"
    elif sim >= 0.65:
        return "ìƒë‹¹í•œ ìœ ì‚¬ë„"
    elif sim >= 0.4:
        return "ì¼ë¶€ ìŸì  ìœ ì‚¬"
    else:
        return "ì°¸ê³  ìˆ˜ì¤€"

# ------------------------
# 1ï¸âƒ£ /analyze
# ------------------------
def analyze_case(request):
    import time
    start = time.time()
    
    print("\n" + "=" * 80)
    print("ğŸš€ analyze_case START")
    print("=" * 80)
    print(f"ì…ë ¥ í…ìŠ¤íŠ¸ ê¸¸ì´: {len(request.case_text)} chars")

    if not request.case_text or not request.case_text.strip():
        raise ValueError("case_text is empty")

    # âœ… case_type ì²˜ë¦¬: ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ ìë™ ì¶”ì •
    if request.case_type:
        # ê¸°ì¡´ ë°©ì‹ (í•˜ìœ„ í˜¸í™˜)
        inferred_type = request.case_type
        confidence = 1.0  # ì‚¬ìš©ìê°€ ì§ì ‘ ì„ íƒí–ˆìœ¼ë¯€ë¡œ 100%
        print(f"ğŸ“Œ ì‚¬ìš©ì ì§€ì • case_type: {inferred_type}")
    else:
        # ìƒˆë¡œìš´ ë°©ì‹ (ìë™ ë¶„ë¥˜)
        inferred_type, confidence = infer_case_type(request.case_text)
        print(f"ğŸ” ìë™ ë¶„ë¥˜: {inferred_type} (ì‹ ë¢°ë„: {confidence:.2f})")
    
    type_label = get_case_type_label(inferred_type)
    type_desc = get_case_type_description(inferred_type, confidence)

    # âœ… ì¿¼ë¦¬ ì„ë² ë”©
    query_vec = model.encode([request.case_text]).astype("float32")

    # âœ… Subset ê²€ìƒ‰ + Fallback
    results = search_with_fallback(
        query_vec=query_vec,
        faiss_index=faiss_index,
        df_full=df_analysis,
        case_type=inferred_type,
        top_k=10,
        fallback_threshold=3
    )

    print(f"\nğŸ“Š ìµœì¢… ê²€ìƒ‰ ê²°ê³¼: {len(results)} ê±´")

    # âœ… í›„ì²˜ë¦¬
    results["similarity_band"] = results["similarity"].apply(similarity_band)
    results["decision_result"] = results["case_text"].apply(extract_decision_result)
    results["risk_score"] = results["decision_result"].map(DECISION_RISK_MAP).fillna(0.5)

    avg_risk = results["risk_score"].mean() if len(results) > 0 else 0.5
    overall_risk = (
        "ë†’ìŒ" if avg_risk >= 0.7 else "ì¤‘ê°„" if avg_risk >= 0.4 else "ë‚®ìŒ"
    )

    top_cases = results.head(5)

    # âœ… ìš”ì•½ ìƒì„±
    try:
        summary = generate_case_summary(
            user_case=request.case_text,
            results_df=top_cases,
            overall_risk_level=overall_risk
        )
    except Exception as e:
        print(f"âš ï¸ ìš”ì•½ ìƒì„± ì˜¤ë¥˜: {e}")
        summary = "ìš”ì•½ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."

    # âœ… ì‘ë‹µ ìƒì„±
    similar_cases_list = []
    
    for idx, (i, r) in enumerate(top_cases.iterrows()):
        case_num_raw = r.get("ì‚¬ê±´ë²ˆí˜¸")
        
        case_id = None
        if pd.notna(case_num_raw):
            normalized = str(case_num_raw).strip()
            if normalized in case_id_to_idx:
                case_id = normalized
        
        similar_cases_list.append({
            "case_id": case_id,
            "case_name": str(r.get("ì‚¬ê±´ëª…", "")),
            "court": str(r.get("ë²•ì›ëª…", "")),
            "case_number": str(case_num_raw) if pd.notna(case_num_raw) else "",
            "decision_type": str(r.get("íŒê²°ìœ í˜•", "íŒê²°")),
            "decision_result": str(r.get("decision_result", "íŒë‹¨ë¶ˆëª…")),
            "similarity": float(r.get("similarity", 0)),
            "case_type_label": str(r.get("ì‚¬ê±´ì¢…ë¥˜ëª…", "")),  # âœ… ì¶”ê°€
            "xai_reason": (
                f"{r['similarity_band']}ì— í•´ë‹¹í•˜ë©° íŒë‹¨ ê²°ê³¼ëŠ” '{r['decision_result']}'ì…ë‹ˆë‹¤."
            ),
        })

    print(f"\nâœ… analyze_case END: {time.time() - start:.2f}s")
    print("=" * 80 + "\n")

    return {
        "overall_risk_level": overall_risk,
        "summary": summary,
        "similar_cases": similar_cases_list,
        # âœ… ìë™ ë¶„ë¥˜ ì •ë³´
        "inferred_case_type": inferred_type,
        "case_type_label": type_label,
        "case_type_confidence": confidence,
        "case_type_description": type_desc,
    }

# ------------------------
# 2ï¸âƒ£ /case/{case_id}/summary
# ------------------------
def get_case_summary(case_id: str) -> CaseSummaryResponse:
    """ì‚¬ê±´ ìš”ì•½ ì¡°íšŒ"""
    case_id_norm = case_id.strip()
    
    if case_id_norm not in case_id_to_idx:
        raise ValueError(f"Case not found: {case_id}")
    
    idx = case_id_to_idx[case_id_norm]
    row = df_full.iloc[idx:idx+1]

    try:
        summary = generate_case_summary(
            user_case="",
            results_df=row,
            overall_risk_level=""
        )
    except Exception as e:
        print(f"âš ï¸ ìš”ì•½ ìƒì„± ì˜¤ë¥˜: {e}")
        summary = "ìš”ì•½ ìƒì„± ë¶ˆê°€"

    return CaseSummaryResponse(case_id=case_id, summary=summary)

# ------------------------
# 3ï¸âƒ£ /case/{case_id}/full
# ------------------------
def get_case_full_text(case_id: str) -> CaseFullTextResponse:
    """íŒë¡€ ì „ë¬¸ ì¡°íšŒ"""
    print(f"ğŸ“‚ get_case_full_text: '{case_id}'")
    
    case_id_norm = case_id.strip()
    
    if case_id_norm not in case_id_to_idx:
        print(f"âŒ Case not found: {case_id}")
        raise ValueError(f"Case not found: {case_id}")
    
    idx = case_id_to_idx[case_id_norm]
    r = df_full.iloc[idx]
    
    full_text = r.get("case_text", "")
    
    if not full_text or pd.isna(full_text):
        print(f"âš ï¸ full_text ë¹„ì–´ìˆìŒ")
        full_text = "íŒë¡€ ì „ë¬¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    else:
        print(f"âœ… full_text ë¡œë“œ ì„±ê³µ: {len(full_text)} chars")
    
    # ìš”ì•½
    try:
        summary = generate_case_summary(
            user_case="",
            results_df=df_full.iloc[idx:idx+1],
            overall_risk_level=""
        )
    except Exception as e:
        print(f"âš ï¸ ìš”ì•½ ìƒì„± ì˜¤ë¥˜: {e}")
        summary = ""

    return CaseFullTextResponse(
        case_id=case_id,
        case_name=str(r.get("ì‚¬ê±´ëª…", "")),
        full_text=full_text,
        summary=summary
    )